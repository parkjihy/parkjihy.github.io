<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>[2023 Convergence Project] Unicorn</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    body { font-family: 'Poppins', sans-serif; background: #f9f9f9; }
    .container { padding: 50px 20px; }
    .btn-back { margin-top: 30px; }
    .content-image { max-width: 80%; }
    .content-image-center { display: block; margin: 30px auto; }
    aside {
      background: #f1f3f5;
      padding: 20px;
      border-radius: 10px;
      margin: 30px 0;
      font-size: 1rem;
    }
  </style>
</head>
<body>

<div class="container">
  <h1>[2023 Convergence Project] Unicorn</h1>
  
  <img src="./img/before_after_.png" 
       alt="Unicorn Representative Image" class="img-fluid content-image content-image-center">

  <aside>
    üí° Role
    <ul>
      <li>Project planning</li>
      <li>Energy consumption prediction data collection and analysis</li>
      <li>AI model development</li>
    </ul>
  </aside>

  <h2>Project Overview</h2>
  <ul>
    <li>Time-series data like building energy usage has high volatility, leading to low prediction accuracy, and deep learning models become more complex as the model size increases.</li>
    <li>Applied Quantization Aware Training (QAT) to the LSTM model, generating quantized weights during training and using them to build an optimized model.</li>
  </ul>

  <h3>Expected Outcomes</h3>
  <ul>
    <li><strong>Improved accuracy:</strong> QAT reduces overfitting and enhances generalization performance.</li>
    <li><strong>Improved training speed:</strong> Quantized weights reduce computation cost and speed up training.</li>
    <li><strong>Model lightweighting:</strong> Reduced memory usage, making it suitable for mobile/embedded systems.</li>
  </ul>

  <img src="./img/log.jpeg" alt="LSTM Architecture" class="img-fluid content-image content-image-center">

  <img src="./img/before_after_.png" alt="Before and After" class="img-fluid content-image content-image-center">

  <h2>Languages / Development Environment</h2>
  <ul>
    <li>Python</li>
    <li>Linux, MobaXterm</li>
  </ul>

  <h2>Achievements</h2>
  <ul>
    <li><strong>1 SCI paper:</strong> 
      <a href="https://ieeexplore.ieee.org/document/10529996" target="_blank">
        Q-LAtte: Quantized Attention-Based Time Series Forecasting in Building Energy Applications (IEEE Access, 2024)
      </a>
    </li>
    <li><strong>1 Patent Application:</strong></li>
  </ul>

  <img src="./img/·Ñê·Ö≥·Ü®·Ñí·Ö•2.png"  class="img-fluid content-image content-image-center">

  <h2>Project Timeline</h2>
  <p>June 2023 ~ December 2023</p>

  <a href="index.html#projects" class="btn btn-primary btn-back">‚Üê Back to Projects</a>
</div>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
